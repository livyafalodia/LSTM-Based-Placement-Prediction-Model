# -*- coding: utf-8 -*-
"""Placement Predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HmdUcnC98mvA35BAR4B39Any9ViRGqpM
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from sklearn.model_selection import train_test_split

file_path = "/content/placement-dataset.csv"  # Update the path if needed
df = pd.read_csv(file_path)

if "Unnamed: 0" in df.columns:
    df = df.drop(columns=["Unnamed: 0"])

X = df[['cgpa', 'iq']].values  # Add more features if available
y = df['placement'].values  # Target (1 = Placed, 0 = Not Placed)

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

X_reshaped = np.reshape(X_scaled, (X_scaled.shape[0], 1, X_scaled.shape[1]))

X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)

model = Sequential([
    LSTM(100, activation='relu', return_sequences=True, input_shape=(1, X_train.shape[2])),
    BatchNormalization(),
    Dropout(0.3),

    LSTM(50, activation='relu', return_sequences=True),
    BatchNormalization(),
    Dropout(0.3),

    LSTM(25, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),

    Dense(1, activation='sigmoid')  # Sigmoid for binary classification
])


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)


loss, accuracy = model.evaluate(X_test, y_test)
print(f"\nðŸ”¹ Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}")

predictions = model.predict(X_test)
predicted_classes = (predictions > 0.5).astype(int)

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='red')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Training & Validation Loss")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Training & Validation Accuracy")
plt.legend()
plt.show()

plt.figure(figsize=(8, 5))
sns.histplot(predictions, bins=20, kde=True, color="blue")
plt.xlabel("Placement Probability")
plt.ylabel("Frequency")
plt.title("Distribution of Predicted Placement Probabilities")
plt.show()

print("\nðŸ”¹ Sample Predictions:\n")
for i in range(5):
    print(f"CGPA: {df.iloc[i]['cgpa']}, IQ: {df.iloc[i]['iq']}, "
          f"Actual Placement: {y_test[i]}, Predicted: {predicted_classes[i][0]} (Probability: {predictions[i][0]:.2f})")